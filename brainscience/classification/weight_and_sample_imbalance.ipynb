{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87bb803f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>symptom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.385714</td>\n",
       "      <td>-0.730334</td>\n",
       "      <td>-0.139520</td>\n",
       "      <td>0.885217</td>\n",
       "      <td>0.185512</td>\n",
       "      <td>-0.092579</td>\n",
       "      <td>1.675729</td>\n",
       "      <td>-0.686223</td>\n",
       "      <td>0.531079</td>\n",
       "      <td>1.260273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310443</td>\n",
       "      <td>0.685676</td>\n",
       "      <td>0.743884</td>\n",
       "      <td>-1.707476</td>\n",
       "      <td>0.409856</td>\n",
       "      <td>0.234790</td>\n",
       "      <td>0.124626</td>\n",
       "      <td>-0.304451</td>\n",
       "      <td>-0.098937</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.139784</td>\n",
       "      <td>0.202991</td>\n",
       "      <td>-0.172729</td>\n",
       "      <td>2.288758</td>\n",
       "      <td>0.832926</td>\n",
       "      <td>-1.270105</td>\n",
       "      <td>-0.541457</td>\n",
       "      <td>-0.299268</td>\n",
       "      <td>-0.662836</td>\n",
       "      <td>-1.111758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347890</td>\n",
       "      <td>0.022021</td>\n",
       "      <td>-0.588785</td>\n",
       "      <td>-2.409142</td>\n",
       "      <td>-0.092867</td>\n",
       "      <td>0.687847</td>\n",
       "      <td>-1.272507</td>\n",
       "      <td>0.852925</td>\n",
       "      <td>-0.070433</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.301588</td>\n",
       "      <td>-1.216219</td>\n",
       "      <td>-0.320328</td>\n",
       "      <td>1.682189</td>\n",
       "      <td>1.250116</td>\n",
       "      <td>-1.544504</td>\n",
       "      <td>-0.439693</td>\n",
       "      <td>0.573244</td>\n",
       "      <td>-0.466864</td>\n",
       "      <td>0.410886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699880</td>\n",
       "      <td>0.722700</td>\n",
       "      <td>-0.565397</td>\n",
       "      <td>-1.177416</td>\n",
       "      <td>1.832512</td>\n",
       "      <td>-1.763520</td>\n",
       "      <td>1.174136</td>\n",
       "      <td>-0.110950</td>\n",
       "      <td>-0.721374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.610831</td>\n",
       "      <td>-0.224714</td>\n",
       "      <td>3.514447</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>-2.178927</td>\n",
       "      <td>1.008115</td>\n",
       "      <td>-0.221103</td>\n",
       "      <td>0.152922</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>-0.069084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100465</td>\n",
       "      <td>1.928904</td>\n",
       "      <td>-0.030931</td>\n",
       "      <td>0.060462</td>\n",
       "      <td>-1.101277</td>\n",
       "      <td>0.496262</td>\n",
       "      <td>-0.477511</td>\n",
       "      <td>1.070145</td>\n",
       "      <td>0.226384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.683467</td>\n",
       "      <td>0.778225</td>\n",
       "      <td>-0.244681</td>\n",
       "      <td>-0.104264</td>\n",
       "      <td>-0.153930</td>\n",
       "      <td>1.351049</td>\n",
       "      <td>0.544877</td>\n",
       "      <td>1.948468</td>\n",
       "      <td>-0.672722</td>\n",
       "      <td>-0.002173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068522</td>\n",
       "      <td>0.431119</td>\n",
       "      <td>1.112156</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>-0.151477</td>\n",
       "      <td>1.208057</td>\n",
       "      <td>-1.728618</td>\n",
       "      <td>-0.297925</td>\n",
       "      <td>-2.181558</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.385714 -0.730334 -0.139520  0.885217  0.185512 -0.092579  1.675729   \n",
       "1 -1.139784  0.202991 -0.172729  2.288758  0.832926 -1.270105 -0.541457   \n",
       "2  0.301588 -1.216219 -0.320328  1.682189  1.250116 -1.544504 -0.439693   \n",
       "3  0.610831 -0.224714  3.514447  0.002929 -2.178927  1.008115 -0.221103   \n",
       "4  0.683467  0.778225 -0.244681 -0.104264 -0.153930  1.351049  0.544877   \n",
       "\n",
       "          8         9        10  ...        42        43        44        45  \\\n",
       "0 -0.686223  0.531079  1.260273  ...  0.310443  0.685676  0.743884 -1.707476   \n",
       "1 -0.299268 -0.662836 -1.111758  ...  0.347890  0.022021 -0.588785 -2.409142   \n",
       "2  0.573244 -0.466864  0.410886  ...  0.699880  0.722700 -0.565397 -1.177416   \n",
       "3  0.152922  0.782051 -0.069084  ...  0.100465  1.928904 -0.030931  0.060462   \n",
       "4  1.948468 -0.672722 -0.002173  ...  0.068522  0.431119  1.112156  0.008301   \n",
       "\n",
       "         46        47        48        49        50  symptom  \n",
       "0  0.409856  0.234790  0.124626 -0.304451 -0.098937        1  \n",
       "1 -0.092867  0.687847 -1.272507  0.852925 -0.070433        1  \n",
       "2  1.832512 -1.763520  1.174136 -0.110950 -0.721374        1  \n",
       "3 -1.101277  0.496262 -0.477511  1.070145  0.226384        1  \n",
       "4 -0.151477  1.208057 -1.728618 -0.297925 -2.181558        1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Class weitht\n",
    "'''Pytorch:\n",
    "多分类：torch.nn.CrossEntropyLoss(weight=...); 二分类/多标签：torch.nn.BCEWithLogitsLoss(pos_weight=...)\n",
    "Tensorflow2/Keras:\n",
    "多分类：tf.nn.weighted_cross_entropy_with_logits(pos_weight=...); 二分类或多分类：model.fit(class_weight=...)'''\n",
    "\n",
    "#Sample weight\n",
    "'''Pytorch:\n",
    "多标签: torch.nn.BCEWithLogitsLoss(weight=...)\n",
    "Tensorflow2/Keras:\n",
    "model.fit(sample_weight=...)\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "from sklearn import metrics\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "ds = pd.read_csv(\"ahc.csv\")\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e511c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide into the training and test data sets.\n",
    "tr = ds.columns[:-1]\n",
    "\n",
    "\n",
    "#X_train,X_test,y_train,y_test = model_selection.train_test_split(ds[tr], ds.churn, test_size=0.25,random_state=67)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c807e60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 2868 neg: 2176 pos: 692\n",
      "Weight for class 0: 0.66\n",
      "Weight for class 1: 2.07\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "total = 2868\n",
    "pos = 692\n",
    "neg = 2176\n",
    "print(f'total: {total}', f'neg: {neg}', f'pos: {pos}')\n",
    "weight_for_0 = (1 / neg) *(total)/2.0\n",
    "weight_for_1 = (1 / pos) *(total)/2.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))\n",
    "\n",
    "#or using sklearn.utils\n",
    "# from sklearn.utils import class_weight\n",
    "\n",
    "# class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                  np.unique(y_train),\n",
    "#                                                  y_train)\n",
    "\n",
    "# model.fit(X_train, y_train, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c4f6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class weight\n",
    "def Catclass(clas, X, target):\n",
    "    acc = []\n",
    "    rec = []\n",
    "    f1 = []\n",
    "    gm = []\n",
    "    mae = []\n",
    "    for train, test in kf.split(X,target): \n",
    "        X_train = X.loc[train]\n",
    "        y_train = target.loc[train]    \n",
    "        \n",
    "    \n",
    "        \n",
    "        #UNDERSAMPLING\n",
    "        \n",
    "        #TomekLinks\n",
    "        #utl = TomekLinks() \n",
    "        #usa_X,usa_y = utl.fit_sample(X_train, y_train)\n",
    "        \n",
    "        \n",
    "      \n",
    "        # The proportion of categories before resampling\n",
    "        #print(y_train.value_counts()/len(y_train))\n",
    "        # The proportion of categories after resampling\n",
    "        #print('After resampling:')\n",
    "        #print(pd.Series(usa_y).value_counts()/len(usa_y))\n",
    "       \n",
    "        \n",
    "        \n",
    "        X_test = X.loc[test]\n",
    "        y_test = target.loc[test]\n",
    "\n",
    "        #accuracy of model prediction and other metrics\n",
    "       \n",
    "        #clas.fit(usa_X,usa_y) # undersampling \n",
    "        \n",
    "        clas.fit(X_train, y_train)\n",
    "        pred = clas.predict(X_test)\n",
    "        print(metrics.classification_report(y_test, pred))\n",
    "        acc.append(metrics.accuracy_score(y_test, pred))\n",
    "        rec.append(metrics.recall_score(y_test, pred))\n",
    "        f1.append(metrics.f1_score(y_test, pred)) \n",
    "        gm.append(geometric_mean_score(y_test, pred))\n",
    "        #mae.append(mean_absolute_error(y_test, pred))\n",
    "    print('Modelprediction-Accuracy: %.4f; Standard Deviation: %.4f' % (np.mean(acc), np.std(acc)))\n",
    "    print('Recall: %.4f; Standard Deviation: %.4f' % (np.mean(rec), np.std(rec)))\n",
    "    print('F1-score: %.4f; Standard Deviation: %.4f' % (np.mean(f1), np.std(f1)))\n",
    "    print('G-means: %.4f; Standard Deviation: %.4f' % (np.mean(gm), np.std(gm))) \n",
    "\n",
    "    #print('MAE: %.4f; Standard Deviation: %.4f' % (np.mean(mae), np.std(mae)))\n",
    "#     results = cross_val_score(clas, X, target, cv=kf, scoring='neg_mean_absolute_error')\n",
    "#     print(results)\n",
    "#     print(\"Accuracy: %.4f (%.4f)\" % (results.mean(), results.std()))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa9c3453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           1       0.00      0.00      0.00     287.0\n",
      "\n",
      "    accuracy                           0.00     287.0\n",
      "   macro avg       0.00      0.00      0.00     287.0\n",
      "weighted avg       0.00      0.00      0.00     287.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           1       0.00      0.00      0.00     287.0\n",
      "\n",
      "    accuracy                           0.00     287.0\n",
      "   macro avg       0.00      0.00      0.00     287.0\n",
      "weighted avg       0.00      0.00      0.00     287.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74       169\n",
      "           1       0.00      0.00      0.00       118\n",
      "\n",
      "    accuracy                           0.59       287\n",
      "   macro avg       0.29      0.50      0.37       287\n",
      "weighted avg       0.35      0.59      0.44       287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       287\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00       287\n",
      "   macro avg       0.50      0.50      0.50       287\n",
      "weighted avg       1.00      1.00      1.00       287\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       287\n",
      "\n",
      "    accuracy                           1.00       287\n",
      "   macro avg       1.00      1.00      1.00       287\n",
      "weighted avg       1.00      1.00      1.00       287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       287\n",
      "\n",
      "    accuracy                           1.00       287\n",
      "   macro avg       1.00      1.00      1.00       287\n",
      "weighted avg       1.00      1.00      1.00       287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       287\n",
      "\n",
      "    accuracy                           1.00       287\n",
      "   macro avg       1.00      1.00      1.00       287\n",
      "weighted avg       1.00      1.00      1.00       287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       287\n",
      "\n",
      "    accuracy                           1.00       287\n",
      "   macro avg       1.00      1.00      1.00       287\n",
      "weighted avg       1.00      1.00      1.00       287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       286\n",
      "\n",
      "    accuracy                           1.00       286\n",
      "   macro avg       1.00      1.00      1.00       286\n",
      "weighted avg       1.00      1.00      1.00       286\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       286\n",
      "\n",
      "    accuracy                           1.00       286\n",
      "   macro avg       1.00      1.00      1.00       286\n",
      "weighted avg       1.00      1.00      1.00       286\n",
      "\n",
      "Modelprediction-Accuracy: 0.7585; Standard Deviation: 0.3982\n",
      "Recall: 0.0000; Standard Deviation: 0.0000\n",
      "F1-score: 0.0000; Standard Deviation: 0.0000\n",
      "G-means: 0.6000; Standard Deviation: 0.4899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "Catclass(RandomForestClassifier(random_state = 67, class_weight = 'balanced'), ds[tr],ds.symptom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bde05c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample weight\n",
    "def Catclass(clas, X, target):\n",
    "    acc = []\n",
    "    rec = []\n",
    "    f1 = []\n",
    "    gm = []\n",
    "    mae = []\n",
    "    for train, test in kf.split(X,target): \n",
    "        X_train = X.loc[train]\n",
    "        y_train = target.loc[train]    \n",
    "        \n",
    "    \n",
    "        \n",
    "        #UNDERSAMPLING\n",
    "        \n",
    "        #TomekLinks\n",
    "        #utl = TomekLinks() \n",
    "        #usa_X,usa_y = utl.fit_sample(X_train, y_train)\n",
    "        \n",
    "        \n",
    "      \n",
    "        # The proportion of categories before resampling\n",
    "        #print(y_train.value_counts()/len(y_train))\n",
    "        # The proportion of categories after resampling\n",
    "        #print('After resampling:')\n",
    "        #print(pd.Series(usa_y).value_counts()/len(usa_y))\n",
    "       \n",
    "        \n",
    "        \n",
    "        X_test = X.loc[test]\n",
    "        y_test = target.loc[test]\n",
    "\n",
    "        #accuracy of model prediction and other metrics\n",
    "       \n",
    "        #clas.fit(usa_X,usa_y) # undersampling \n",
    "        \n",
    "        '''The “balanced” mode uses the values of y to automatically adjust\n",
    "        weights inversely proportional to class frequencies in the input data: n_samples / (n_classes * np.bincount(y)).'''\n",
    "        sample_weights = class_weight.compute_sample_weight('balanced', y_train)\n",
    "        \n",
    "        clas.fit(X_train, y_train, sample_weight = sample_weights)\n",
    "        pred = clas.predict(X_test)\n",
    "        print(metrics.classification_report(y_test, pred))\n",
    "        acc.append(metrics.accuracy_score(y_test, pred))\n",
    "        rec.append(metrics.recall_score(y_test, pred))\n",
    "        f1.append(metrics.f1_score(y_test, pred)) \n",
    "        gm.append(geometric_mean_score(y_test, pred))\n",
    "        #mae.append(mean_absolute_error(y_test, pred))\n",
    "    print('Modelprediction-Accuracy: %.4f; Standard Deviation: %.4f' % (np.mean(acc), np.std(acc)))\n",
    "    print('Recall: %.4f; Standard Deviation: %.4f' % (np.mean(rec), np.std(rec)))\n",
    "    print('F1-score: %.4f; Standard Deviation: %.4f' % (np.mean(f1), np.std(f1)))\n",
    "    print('G-means: %.4f; Standard Deviation: %.4f' % (np.mean(gm), np.std(gm))) \n",
    "\n",
    "    #print('MAE: %.4f; Standard Deviation: %.4f' % (np.mean(mae), np.std(mae)))\n",
    "#     results = cross_val_score(clas, X, target, cv=kf, scoring='neg_mean_absolute_error')\n",
    "#     print(results)\n",
    "#     print(\"Accuracy: %.4f (%.4f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6876cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           1       0.00      0.00      0.00     287.0\n",
      "\n",
      "    accuracy                           0.00     287.0\n",
      "   macro avg       0.00      0.00      0.00     287.0\n",
      "weighted avg       0.00      0.00      0.00     287.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           1       0.00      0.00      0.00     287.0\n",
      "\n",
      "    accuracy                           0.00     287.0\n",
      "   macro avg       0.00      0.00      0.00     287.0\n",
      "weighted avg       0.00      0.00      0.00     287.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74       169\n",
      "           1       0.00      0.00      0.00       118\n",
      "\n",
      "    accuracy                           0.59       287\n",
      "   macro avg       0.29      0.50      0.37       287\n",
      "weighted avg       0.35      0.59      0.44       287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       287\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00       287\n",
      "   macro avg       0.50      0.50      0.50       287\n",
      "weighted avg       1.00      1.00      1.00       287\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       287\n",
      "\n",
      "    accuracy                           1.00       287\n",
      "   macro avg       1.00      1.00      1.00       287\n",
      "weighted avg       1.00      1.00      1.00       287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       287\n",
      "\n",
      "    accuracy                           1.00       287\n",
      "   macro avg       1.00      1.00      1.00       287\n",
      "weighted avg       1.00      1.00      1.00       287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       287\n",
      "\n",
      "    accuracy                           1.00       287\n",
      "   macro avg       1.00      1.00      1.00       287\n",
      "weighted avg       1.00      1.00      1.00       287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       287\n",
      "\n",
      "    accuracy                           1.00       287\n",
      "   macro avg       1.00      1.00      1.00       287\n",
      "weighted avg       1.00      1.00      1.00       287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       286\n",
      "\n",
      "    accuracy                           1.00       286\n",
      "   macro avg       1.00      1.00      1.00       286\n",
      "weighted avg       1.00      1.00      1.00       286\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       286\n",
      "\n",
      "    accuracy                           1.00       286\n",
      "   macro avg       1.00      1.00      1.00       286\n",
      "weighted avg       1.00      1.00      1.00       286\n",
      "\n",
      "Modelprediction-Accuracy: 0.7585; Standard Deviation: 0.3982\n",
      "Recall: 0.0000; Standard Deviation: 0.0000\n",
      "F1-score: 0.0000; Standard Deviation: 0.0000\n",
      "G-means: 0.6000; Standard Deviation: 0.4899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Py\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "Catclass(RandomForestClassifier(random_state = 67), ds[tr],ds.symptom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
